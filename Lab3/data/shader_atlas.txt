//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
multi_pass basic.vs light_multi_pass.fs
single_pass basic.vs light_single_pass.fs
gbuffers basic.vs gbuffers.fs
deferred basic.vs deferred.fs
deferred_ambient quad.vs deferred_ambient.fs
pbr_multi basic.vs pbr_multi.fs
deferred_pbr basic.vs deferred_pbr.fs
col_corr quad.vs col_corr.fs
ssao quad.vs ssao.fs
ssao_plus quad.vs ssao_plus.fs
probe basic.vs probe.fs
irradiance_deferred quad.vs irradiance_deferred.fs
irradiance_forward basic.vs irradiance_forward.fs
reflection_probe basic.vs reflection_probe.fs
reflections_deferred quad.vs reflections_deferred.fs
skybox basic.vs skybox.fs
volumetric_deferred quad.vs volumetric_deferred.fs
volumetric_deferred_nondir basic.vs volumetric_deferred_nondir.fs
decal basic.vs decal.fs
saturation quad.vs saturation.fs
lens_distortion quad.vs lens_distortion.fs
contrast quad.vs contrast.fs
blur quad.vs blur.fs
mix quad.vs mix.fs
threshold quad.vs threshold.fs
motionblur quad.vs motionblur.fs
depth_field quad.vs depth_field.fs
antialiasing quad.vs antialiasing.fs
depth quad.vs depth.fs

// ------------------------------ Uniforms ------------------------------
\light_uniforms
uniform vec3 u_ambient_light;

uniform int u_light_type;
uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform float u_light_max_distance;
uniform vec3 u_light_direction;
uniform float u_light_cone_cos;
uniform float u_light_cone_exp;

uniform int u_light_cast_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_light_shadowmap_vpm;
uniform float u_light_shadow_bias;
uniform int u_shadow_i;
uniform vec4 u_map_piece;


\texture_uniforms

uniform sampler2D u_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_occlusion_texture;
uniform sampler2D u_met_rough_texture;
uniform float u_metallic_factor;
uniform float u_roughness_factor;
uniform vec3 u_emissive_factor;

uniform samplerCube u_skybox_texture;
uniform int u_scene_reflections;
uniform int u_has_planar_reflections;
uniform sampler2D u_planar_reflections_texture;

\gbuffer_texture_uniforms

uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_gb2_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_ssao_texture;
uniform int u_emissive_flag;


//------------------------------Functions -------------------------------
\normalmap_functions

mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}

vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
	normal_pixel = normal_pixel * 255./127. - 128./127.;
	mat3 TBN = cotangent_frame(N, WP, uv);
	return normalize(TBN * normal_pixel);
}

\degamma
// from gamma (perception) values to linear values
vec3 degamma(vec3 c)
{
	return pow(c,vec3(2.2));
}

// from linear values to gamma (perception) values
vec3 gamma(vec3 c)
{
	return pow( c, vec3(1.0/2.2));
}

\light_functions_multi

// we define this variables here because only multipass uses them, but since deferred also
// needs this functions, we need to define them to avoid errors in computeN function even though deferred does not use them

in vec3 v_normal;
uniform sampler2D u_normal_texture;
uniform int u_normal_text_bool;

// Save computations related to light
struct LightStruct{
	vec3 L;
	vec3 D;
	vec3 N;
	vec3 V;
	vec3 R;
	vec3 H;

	vec3 world_position;

	float NdotL;
	float LdotD;
	float NdotH;
	float NdotV;
	float LdotH;

	float light_dist;

	float spot_factor;
	float att_factor;
	float shadow_factor;
}LightComp;

// L vector for point and spot lights
void computeL_point(inout LightStruct lc){
	// Distance from current point to light
	vec3 L = u_light_position - lc.world_position;
	// Modulus			
	lc.light_dist = length(L);
	// Normalize L
	lc.L = L/lc.light_dist;
}

// L vector for directional light
void computeL_directional(inout LightStruct lc){
	// All points take the same light direction
	vec3 L = u_light_direction;
	lc.light_dist = length(L);
	lc.L = L/lc.light_dist;
}

void computeN(inout LightStruct lc){
	vec3 V = normalize(u_camera_position - lc.world_position);
	vec3 normal_pixel = texture2D( u_normal_texture, v_uv ).xyz; 
	vec3 v_N = normalize(v_normal);
	// if there is a normal texture, compute the normal according to it
	if (u_normal_text_bool == 1)
		lc.N = perturbNormal(v_N, V, v_uv, normal_pixel);
	else
		lc.N = v_N;
}

void computeNdotL(inout LightStruct lc){
	lc.NdotL = clamp(dot(lc.L,lc.N), 0.0, 1.0);
}

void computeSpotFactor(inout LightStruct lc){
	lc.D = normalize(u_light_direction);
	lc.LdotD = dot(-lc.L, lc.D);
	// check if point inside the spotlight
	if (lc.LdotD >= u_light_cone_cos){
		// compute how much it is inside
		lc.spot_factor = pow(lc.LdotD, u_light_cone_exp);	
	}
	else{
		lc.spot_factor = 0.0;
	}	
}

void computeAttenuation(inout LightStruct lc){
	float att_factor = u_light_max_distance - lc.light_dist;
	att_factor /= u_light_max_distance;
	att_factor = max(att_factor, 0.0);
	// apply quadratic attenuation
	lc.att_factor = pow(att_factor,2);
}

void testShadowMap(inout LightStruct lc){
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_light_shadowmap_vpm * vec4(lc.world_position, 1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;
	
	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_light_shadow_bias) / proj_pos.w;
	
	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;
	
	//read depth from depth buffer in [0..+1] non-linear
	vec4 scale_factor = u_map_piece;
	vec2 sh_uv = vec2(shadow_uv.x*scale_factor[0] + scale_factor[2], shadow_uv.y*scale_factor[1] + scale_factor[3]);
	float shadow_depth = texture( u_light_shadowmap, sh_uv).x;
	
	//compute final shadow factor by comparing
	lc.shadow_factor = 1.0;
	
	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		lc.shadow_factor = 0.0;
		
	//We must see if it is outside the sides
	if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
		lc.shadow_factor = 1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		lc.shadow_factor = 1.0;

}

vec3 computeLight(inout LightStruct lc, vec3 light_color){
	// Point
	if (u_light_type == 1){
		computeL_point(lc);
	}

	// Spot
	else if (u_light_type == 2){
		computeL_point(lc);
		computeSpotFactor(lc);
	}

	// Directional
	else if (u_light_type == 3){
		computeL_directional(lc);
	}


	computeNdotL(lc);


	if (u_light_cast_shadows == 1){
		testShadowMap(lc);
	}

	computeAttenuation(lc);
	vec3 light = light_color * lc.NdotL * lc.att_factor * lc.spot_factor * lc.shadow_factor;
	return light;
}

\light_functions_single

// Save computations related to light
struct LightStruct{
	vec3 L;
	vec3 D;
	vec3 N;

	float NdotL;
	float LdotD;
	float light_dist;

	float spot_factor;
	float att_factor;
	float shadow_factor;
}LightComp;

// L vector for point and spot lights
void computeL_point(inout LightStruct lc, int i){
	// Distance from current point to light
	vec3 L = u_lights_position[i] - v_world_position;
	// Modulus			
	lc.light_dist = length(L);
	// Normalize L
	lc.L = L/lc.light_dist;
}

// L vector for directional light
void computeL_directional(inout LightStruct lc, int i){
	// All points take the same light direction
	vec3 L = u_lights_direction[i];
	lc.light_dist = length(L);
	lc.L = L/lc.light_dist;
}

void computeNdotL(inout LightStruct lc){
	vec3 V = normalize(u_camera_position - v_world_position);
	vec3 normal_pixel = texture2D( u_normal_texture, v_uv ).xyz; 
	vec3 N = normalize(v_normal);
	// if there is a normal texture, compute the normal according to it
	if (u_normal_text_bool == 1)
		lc.N = perturbNormal(N, V, v_uv, normal_pixel);
	else
		lc.N = N;
	lc.NdotL = clamp(dot(lc.L,lc.N), 0.0, 1.0);
}

void computeSpotFactor(inout LightStruct lc, int i){
	lc.D = normalize(u_lights_direction[i]);
	lc.LdotD = dot(-lc.L, lc.D);
	// check if point inside the spotlight
	if (lc.LdotD >= u_lights_cone_cos[i]){
		// compute how much it is inside
		lc.spot_factor = pow(lc.LdotD, u_lights_cone_exp[i]);	
	}
	else{
		lc.spot_factor = 0.0;
	}	
}

void computeAttenuation(inout LightStruct lc, int i){
	float att_factor = u_lights_max_distance[i] - lc.light_dist;
	att_factor /= u_lights_max_distance[i];
	att_factor = max(att_factor, 0.0);
	// apply quadratic attenuation
	lc.att_factor = pow(att_factor,2);
}

// Assign each light to their corresponding space in the shadowmap atlas
vec4 assignMapPiece(int index){
	int num_cols = int(ceil(sqrt(u_num_lights_shadow)));
	int num_rows;

	if (u_num_lights_shadow <= num_cols * (num_cols - 1))
		num_rows = num_cols - 1;
	else
		num_rows = num_cols;

	float min_cols_rows = (num_cols < num_rows) ? num_cols : num_rows;
	float size = 1 / min_cols_rows;

	int i_col = index % num_cols;
	int i_row = index / num_cols;

	return vec4(size, size, i_col * size, i_row * size);
}

void testShadowMap(inout LightStruct lc, int i, int sh_i){
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_lights_shadowmap_vpm[sh_i] * vec4(v_world_position,1.0);
	
	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;
	
	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_lights_shadow_bias[i]) / proj_pos.w;
	
	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;
	
	//read depth from depth buffer in [0..+1] non-linear
	vec4 scale_factor = assignMapPiece(sh_i);
	vec2 sh_uv = vec2(shadow_uv.x*scale_factor[0] + scale_factor[2], shadow_uv.y*scale_factor[1] + scale_factor[3]);
	float shadow_depth = texture( u_lights_shadowmap, sh_uv).x;
	
	//compute final shadow factor by comparing
	lc.shadow_factor = 1.0;
	
	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		lc.shadow_factor = 0.0;
		
	//We must see if it is outside the sides
	if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
		lc.shadow_factor = 1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		lc.shadow_factor = 1.0;
}

\pbr_functions

// Normal Distribution Function using GGX Distribution
float D_GGX (const in float NoH, const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

// Fresnel term with colorized fresnel
vec3 F_Schlick( const in float VoH, const in vec3 f0)
{ 
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

// Diffuse Reflections: Disney BRDF using retro-reflections using F term, this is much more complex!!
vec3 Fd_Burley ( const in float NoV, const in float NoL, const in float LoH, const in float linearRoughness)
{
        vec3 f90 = 0.5 + 2.0 * vec3(linearRoughness) * LoH * LoH;

        vec3 lightScatter = F_Schlick(NoL, f90);
        vec3 viewScatter  = F_Schlick(NoV, f90);
        return lightScatter * viewScatter * RECIPROCAL_PI;
}

//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH )
{
	float a = roughness * roughness;

	// Normal Distribution Function
	float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}

\ssao_functions
vec3 rotateY( float angle, vec3 delta )
{
	float s0 = sin(angle);
	float c0 = cos(angle);
	return vec3( delta.x * c0 - delta.z * s0, delta.y, delta.x * s0 + delta.z * c0  );
}

mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}


\irradiance_functions

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;

struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}



// ------------------------------ SHADERS --------------------------------
\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

uniform float u_time;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}
//--------------------------------- Quad ----------------------------------
\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_coord;
out vec2 v_uv;

void main()
{	
	v_uv = a_coord;
	gl_Position = vec4( a_vertex, 1.0 );
}

//---------------------------------- Flat --------------------------------
\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}

//--------------------------------- Texture -------------------------------
\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}

//------------------------------------ Singlepass ----------------------------
\light_single_pass.fs
#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform vec3 u_camera_position;

// Color correction
uniform int u_gamma;

//Textures
uniform int u_texture2show;
uniform int u_normal_text_bool;
uniform sampler2D u_normal_texture;

// Light parameters
uniform vec3 u_ambient_light;

#define MAX_LIGHTS 10
uniform int u_lights_type[MAX_LIGHTS];
uniform vec3 u_lights_position[MAX_LIGHTS];
uniform vec3 u_lights_color[MAX_LIGHTS];
uniform float u_lights_max_distance[MAX_LIGHTS];
uniform vec3 u_lights_direction[MAX_LIGHTS];
uniform float u_lights_cone_cos[MAX_LIGHTS];
uniform float u_lights_cone_exp[MAX_LIGHTS];

uniform int u_num_lights_shadow;
uniform int u_lights_cast_shadows[MAX_LIGHTS];
uniform sampler2D u_lights_shadowmap;
uniform mat4 u_lights_shadowmap_vpm[MAX_LIGHTS];
uniform float u_lights_shadow_bias[MAX_LIGHTS];

out vec4 FragColor;

#include texture_uniforms
#include normalmap_functions
#include degamma
#include light_functions_single

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;

	// Emissive
	vec3 emissive = texture( u_emissive_texture, v_uv ).xyz;
	vec3 light = vec3(u_ambient_light);
	if (u_gamma == 1)
		color.xyz = degamma(color.xyz);
		light = degamma(light);
		emissive = degamma(emissive + u_emissive_factor);

	// index to store the number of lights casting shadows
	int l_shadow_i = 0;
	// Iterate lights
	for (int i = 0; i < MAX_LIGHTS; i++) {
		LightComp = LightStruct(
			vec3(0.0, 0.0, 0.0), //L
			vec3(0.0, 0.0, 0.0), //D
			vec3(0.0, 0.0, 0.0), //N

			0.0, // NdotL
			0.0, // LdotD
			0.0, // light dist

			1.0, // spot factor
			1.0, // attenuation factor
			1.0 // shadow_factor
		);

		vec3 linear_light_color = u_lights_color[i];

		if (u_gamma == 1)
			linear_light_color = degamma(u_lights_color[i]);
			
		// Point
		if (u_lights_type[i] == 1){
			computeL_point(LightComp, i);
		}

		// Spot
		else if (u_lights_type[i] == 2){
			computeL_point(LightComp, i);
			computeSpotFactor(LightComp, i);
		}

		// Directional
		else if (u_lights_type[i] == 3){
			computeL_directional(LightComp, i);
		}

		// didn't make it to pass multiple textures to the shader so shadowmaps are not working for singlepass
		if (u_lights_cast_shadows[i] == 1){
			testShadowMap(LightComp, i, l_shadow_i);
			l_shadow_i += 1;
		}

		computeNdotL(LightComp);
		computeAttenuation(LightComp, i);
		light += linear_light_color * LightComp.NdotL * LightComp.att_factor * LightComp.spot_factor  * LightComp.shadow_factor;
	}

	// Apply other textures
	//Emissive
	light += emissive;

	// Occlusion can be either in the met_rou or occlusion texture
	light *= texture( u_occlusion_texture, v_uv ).x;
	
	// Occlusion
	// x coord has occlusion map
	light *= texture( u_met_rough_texture, v_uv ).x;

	color.xyz *= light;

	if (u_gamma == 1)
		color.xyz = gamma(color.xyz);

	// Debug textures
	// Normal
	if (u_texture2show == 1){
		color.xyz = LightComp.N;
	}

	// Occlusion
	if(u_texture2show == 2){
		color.xyz = vec3(texture( u_met_rough_texture, v_uv ).x);
		color.xyz *= texture(u_occlusion_texture, v_uv).x;
	}
	// Emissive
	if(u_texture2show == 3)
		color.xyz = emissive;

	FragColor = color;

}

//----------------------------------- Multipass -----------------------------
\light_multi_pass.fs
#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec2 v_uv;
in vec4 v_color;

uniform int u_light_is_first;

uniform vec3 u_camera_position;
uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform vec2 u_iRes;

// Color correction
uniform int u_gamma;

//Textures
uniform int u_texture2show;

out vec4 FragColor;

#include texture_uniforms
#include light_uniforms
#include normalmap_functions
#include degamma
#include light_functions_multi

void main()
{
	LightComp = LightStruct(
		vec3(0.0, 0.0, 0.0), //L
		vec3(0.0, 0.0, 0.0), //D
		vec3(0.0, 0.0, 0.0), //N
		vec3(0.0, 0.0, 0.0), //V
		vec3(0.0, 0.0, 0.0), //R
		vec3(0.0, 0.0, 0.0), //H

		vec3(0.0, 0.0, 0.0), //world_position

		0.0, // NdotL
		0.0, // LdotD
		0.0, // NdotH
		0.0, // NdotV
		0.0, // LdotH

		0.0, // light dist

		1.0, // spot factor
		1.0, // attenuation factor
		1.0 // shadow_factor
	);

	LightComp.world_position = v_world_position;

	vec2 uv = v_uv;
	vec4 color = u_color;
	vec2 uv_screen = gl_FragCoord.xy * u_iRes;
	// invertimos la x de izquierda a derecha para que los reflejos no se vean al revés
	uv_screen.x = 1.0 - uv_screen.x;

	vec4 texture_color = texture( u_texture, v_uv );
	vec4 met_rough = texture(u_met_rough_texture, uv);
	vec3 emissive = texture( u_emissive_texture, v_uv ).xyz;

	vec3 planar_reflection_color = vec3(0.0);
	// CONTROLAMOS EL CASO EN EL QUE UNA MESH ESTÁ POR DEBAJO DEL SUELO, PARA QUE LA FLIPPED_CAMERA NO LO PINTE
	if (u_has_planar_reflections == 0 && v_world_position.y < 0)
		discard;

	// AHORA ESTAMOS MIRANDO QUE SOLO EL SUELO REFLECTE VIENDO LA ALTURA DEL PIXEL, PERO ES UN POCO CUTRE
	if (u_has_planar_reflections == 1 && abs(v_world_position.y) < 0.1)
		planar_reflection_color = texture(u_planar_reflections_texture, uv_screen).xyz;
	
	vec3 light = u_ambient_light;
	vec3 light_color = u_light_color;

	// V YA SE CALCULA DENTRO DE LAS FUNCIONES POINT, SPOT.. HAY QUE REVISARLO
	LightComp.V = normalize(v_world_position - u_camera_position);
	computeN(LightComp);
	LightComp.R = reflect(LightComp.V, LightComp.N);

	vec3 reflection_color = vec3(0.0);
	if (u_scene_reflections == 1){
		// BAJAMOS 4 VALORES SEGUN EL ROUGHNESS PARA QUE ALGUNAS PARTES REFLEJEN MÁS MATE
		reflection_color = textureLod(u_skybox_texture, LightComp.R, met_rough.y * 4.0).xyz;
		//reflection_color = texture(u_skybox_texture, LightComp.R).xyz;
	}


	if (u_gamma == 1){
		color.xyz = degamma(u_color.xyz);
		texture_color.xyz = degamma(texture_color.xyz);
		light = degamma(light);
		light_color = degamma(light_color);
		emissive = degamma(emissive + u_emissive_factor);
		planar_reflection_color = degamma(planar_reflection_color);
		reflection_color = degamma(reflection_color);
	}

	color *= texture_color;
	if (u_has_planar_reflections == 1 && abs(v_world_position.y) < 0.1)
		color.xyz = mix(color.xyz, planar_reflection_color, 0.5);

	if (u_scene_reflections == 1){
		//float reflection_factor = 1.0;
		float reflection_factor = met_rough.z + u_metallic_factor;
		color.xyz = mix(color.xyz, reflection_color, reflection_factor);
	}

	if(color.a < u_alpha_cutoff)
		discard;

	light += computeLight(LightComp, light_color);

	// Apply other textures
	light += emissive;

	// Occlusion
	// x coord has occlusion map
	float occ_factor = texture( u_met_rough_texture, v_uv ).x;
	// Occlusion can be either in the met_rou or occlusion texture
	occ_factor += texture( u_occlusion_texture, v_uv ).x;
	light *= occ_factor;

	color.xyz *= light;

	// Debug textures
	// Normal
	if (u_texture2show == 1){
		color.xyz = LightComp.N;
	}

	// Occlusion
	if(u_texture2show == 2){
		color.xyz = vec3(texture( u_met_rough_texture, v_uv ).x);
		color.xyz *= texture(u_occlusion_texture, v_uv).x;
	}
	// Emissive
	if(u_texture2show == 3)
		color.xyz = emissive;
	
	// seteamos el alpha a 0 a partir de la segunda iteración para que no se aplique gamma correction
	if (u_light_is_first == 0)
		color.a = 0.0;
		
	FragColor = color;
	//FragColor = vec4(light, 1.0);
}

// ----------------------------------- GBuffers -----------------------------
\gbuffers.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec3 u_camera_position;
uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;

// Textures
uniform int u_normal_text_bool;
uniform sampler2D u_normal_texture;

// gbuffers out
layout(location = 0) out vec4 GB0;
layout(location = 1) out vec4 GB1;
layout(location = 2) out vec4 GB2;

#include texture_uniforms
#include normalmap_functions

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N;
	vec3 V = normalize(u_camera_position - v_world_position);
	vec3 normal_pixel = texture2D( u_normal_texture, v_uv ).xyz; 
	vec3 v_N = normalize(v_normal);
	// if there is a normal texture, compute the normal according to it
	if (u_normal_text_bool == 1)
		N = perturbNormal(v_N, V, v_uv, normal_pixel);
	else
		N = v_N;

	// Apply other textures
	// Emissive
	vec3 emissive = texture( u_emissive_texture, v_uv ).xyz + u_emissive_factor;

	// Occlusion
	// x coord has occlusion map
	float occlusion_factor = texture( u_met_rough_texture, v_uv ).x;
	// Occlusion can be either in the met_rou or occlusion texture
	occlusion_factor += texture( u_occlusion_texture, v_uv ).x;

	// Roughness
	float roughness = texture(u_met_rough_texture, v_uv).y + u_roughness_factor;
	// Metalness
	float metalness = texture(u_met_rough_texture, v_uv).z + u_metallic_factor;

	// don't need to save the alpha
	GB0 = vec4(color.xyz, roughness);
	// to recover negative values
	GB1 = vec4(N * 0.5 + vec3(0.5), metalness);
	//GB2 = vec4(occlusion_factor);
	GB2 = vec4(emissive, occlusion_factor);
	//GB2 = vec4(metalness);

}

//------------------------------- Deferred Ambient ---------------------------
\deferred_ambient.fs
// cuando no hay luces se llama a este shader

#version 330 core

in vec2 v_uv;

uniform vec3 u_camera_position;
uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform mat4 u_viewprojection;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

// Light parameters
uniform vec3 u_ambient_light;

// Color correction
uniform int u_gamma;

out vec4 FragColor;

#include gbuffer_texture_uniforms
#include degamma


void main()
{	
	vec2 uv = v_uv;

	vec4 gb0_color = texture(u_gb0_texture, uv);
	//vec4 gb1_color = texture(u_gb1_texture, uv);
	vec4 gb2_color = texture(u_gb2_texture, uv);

	vec4 color = vec4(gb0_color.xyz, 1.0);
	vec3 ambient_light = u_ambient_light;

	// Emissive
	vec3 emissive = gb2_color.xyz;

	if (u_gamma == 1){
		color.xyz = degamma(color.xyz);
		ambient_light = degamma(ambient_light);
		emissive = degamma(emissive);
	}

	float ao_factor = texture(u_ssao_texture, uv).x;

	vec3 light = ambient_light * ao_factor;
	light += emissive;

	// Apply other textures
	// Occlusion (Occlusion value is only in one coordinate)
	light *= gb0_color.w;

	color.xyz *= light;

	FragColor = color;
}

//-------------------------------- Deferred ---------------------------------
\deferred.fs
#version 330 core

in vec2 v_uv;

uniform vec3 u_camera_position;
uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec2 u_camera_nearfar;

uniform mat4 u_viewprojection;

//uniform int u_normal_text_bool;
//uniform int u_texture2show;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

// Color correction
uniform int u_gamma;

out vec4 FragColor;

#include gbuffer_texture_uniforms
#include light_uniforms 
#include normalmap_functions
#include degamma
#include light_functions_multi

void main()
{
	LightComp = LightStruct(
		vec3(0.0, 0.0, 0.0), //L
		vec3(0.0, 0.0, 0.0), //D
		vec3(0.0, 0.0, 0.0), //N
		vec3(0.0, 0.0, 0.0), //V
		vec3(0.0, 0.0, 0.0), //R
		vec3(0.0, 0.0, 0.0), //H

		vec3(0.0, 0.0, 0.0), //World pos

		0.0, // NdotL
		0.0, // LdotD
		0.0, // NdotH
		0.0, // NdotV
		0.0, // LdotH

		0.0, // light dist

		1.0, // spot factor
		1.0, // attenuation factor
		1.0 // shadow_factor
	);
	
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	vec4 gb0_color = texture(u_gb0_texture, uv); // Color + metalness
	vec4 gb1_color = texture(u_gb1_texture, uv); // Normal + roughness
	vec4 gb2_color = texture(u_gb2_texture, uv); // Emissive + occlusion
	float depth = texture( u_depth_texture, uv ).x;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	LightComp.world_position = proj_worldpos.xyz / proj_worldpos.w;

	LightComp.N = normalize(gb1_color.xyz * 2.0 - vec3(1.0)); // PASAMOS DE [0, 1] A [-1, 1]

	vec4 color = vec4(gb0_color.xyz, 1.0);
	float ao_factor = texture(u_ssao_texture, uv).x;

	vec3 light = u_ambient_light;

	vec3 light_color = u_light_color;
	if (u_gamma == 1){
		color.xyz = degamma(color.xyz);
		light = degamma(light);
		light_color = degamma(light_color);
		gb2_color.xyz = degamma(gb2_color.xyz);
	}

	light *= ao_factor;

	// Point
	if (u_light_type == 1){
		computeL_point(LightComp);
	}

	// Spot
	else if (u_light_type == 2){
		computeL_point(LightComp);
		computeSpotFactor(LightComp);
	}

	// Directional
	else if (u_light_type == 3){
		computeL_directional(LightComp);
	}

	computeNdotL(LightComp);

	if (u_light_cast_shadows == 1){
		testShadowMap(LightComp);
	}

	computeAttenuation(LightComp);
	light += light_color * LightComp.NdotL * LightComp.att_factor * LightComp.spot_factor * LightComp.shadow_factor;

	// Apply other textures
	// Emissive
	if (u_emissive_flag == 1)
		light += gb2_color.xyz;

	// Occlusion
	// Occlusion value is only in one coordinate
	light *= gb2_color.w;

	color.xyz *= light;

	FragColor = color;
	//FragColor = vec4(gb2_color.xyz+light,1.0);
}

//------------------------------ Color Correction ---------------------------
\col_corr.fs
#version 330 core
in vec2 v_uv;
in vec4 v_color;

uniform int u_gamma;
uniform int u_tonemapping;
//uniform sampler2D u_gb0_texture;
uniform sampler2D u_screen_texture;
uniform sampler2D u_depth_texture;
uniform float u_lumwhite2;
uniform float u_average_lum;
uniform float u_scale;

out vec4 FragColor;


vec3 gamma(vec3 c)
{
	return pow(c,vec3(1.0/2.2));
}

void main(){
	vec4 color = texture(u_screen_texture, v_uv);
	vec3 rgb = color.xyz;
	float depth = texture(u_depth_texture, v_uv).x;
	// discard background pixels to avoid artifacts
	if (depth == 1.0){
		discard;
	}

	if (u_tonemapping == 1){
		float lum = dot(rgb, vec3(0.2126, 0.7152, 0.0722));
		float L = (u_scale * u_average_lum) * lum;
		float Ld = (L * (1.0 + L * u_lumwhite2)) / (1.0 + L);
		rgb = (rgb / lum) * Ld;
		rgb = max(rgb,vec3(0.001));
	}

	// Aplicamos gamma solo a los objetos sin transparencia (sobretodo para los vidrios) dejando un pequeño
	// margen de 0.1 ya que el chasis del coche por ejemplo tiene un poco de transparencia pero queremos aplicarle gamma
	if (u_gamma == 1 && color.w >= 0.9)
		rgb = gamma(rgb);
	
	FragColor = vec4( rgb, color.a );
}


//----------------------------- PBR Multipass -------------------------------
\pbr_multi.fs
#version 330 core

#define PI 3.14159265358979323846
#define RECIPROCAL_PI 0.3183098861837697

in vec3 v_position;
in vec3 v_world_position;
in vec2 v_uv;
in vec4 v_color;

uniform int u_light_is_first;

uniform vec3 u_camera_position;
uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;

// Color correction
uniform int u_gamma;

uniform int u_texture2show;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

out vec4 FragColor;

#include texture_uniforms
#include light_uniforms
#include normalmap_functions
#include light_functions_multi
#include degamma
#include pbr_functions

void main()
{
	LightComp = LightStruct(
		vec3(0.0, 0.0, 0.0), //L
		vec3(0.0, 0.0, 0.0), //D
		vec3(0.0, 0.0, 0.0), //N
		vec3(0.0, 0.0, 0.0), //V
		vec3(0.0, 0.0, 0.0), //R
		vec3(0.0, 0.0, 0.0), //H

		vec3(0.0, 0.0, 0.0), //World pos

		0.0, // NdotL
		0.0, // LdotD
		0.0, // NdotH
		0.0, // NdotV
		0.0, // LdotH

		0.0, // light dist

		1.0, // spot factor
		1.0, // attenuation factor
		1.0 // shadow_factor
	);

	vec2 uv = v_uv;
	vec2 uv_screen = gl_FragCoord.xy * u_iRes;
	// invertimos la x de izquierda a derecha para que los reflejos no se vean al revés
	uv_screen.x = 1.0 - uv_screen.x;

	vec4 color = u_color;
	vec4 color_texture = texture(u_texture, uv);
	vec4 emissive = texture(u_emissive_texture, uv);
	emissive.xyz += u_emissive_factor;
	vec4 met_rough = texture(u_met_rough_texture, uv);
	float occlusion = texture(u_occlusion_texture, uv).x;

	LightComp.world_position = v_world_position;
	
	if (color.a < u_alpha_cutoff)
		discard;

	computeN(LightComp);

	//float metalness = 1.0;
	float metalness = met_rough.z + u_metallic_factor;
	float roughness = met_rough.y + u_roughness_factor;

	vec3 planar_reflection_color = vec3(0.0);
	if (u_has_planar_reflections == 0 && v_world_position.y < 0)
		discard;

	if (u_has_planar_reflections == 1 && abs(v_world_position.y) < 0.1)
		planar_reflection_color = texture(u_planar_reflections_texture, uv_screen).xyz;

	// V YA SE CALCULA DENTRO DE LAS FUNCIONES POINT, SPOT.. HAY QUE REVISARLO
	LightComp.V = normalize(v_world_position - u_camera_position);
	computeN(LightComp);
	LightComp.R = reflect(LightComp.V, LightComp.N);

	vec3 reflection_color = vec3(0.0);
	if (u_scene_reflections == 1){
		reflection_color = textureLod(u_skybox_texture, LightComp.R, roughness * 4.0).xyz;
		//reflection_color = texture(u_skybox_texture, LightComp.R).xyz;
	}

	vec3 light = vec3(u_ambient_light);

	vec3 light_color = u_light_color;

	if (u_gamma == 1){
		color.xyz = degamma(color.xyz);
		color_texture.xyz = degamma(color_texture.xyz);
		light = degamma(light);
		light_color = degamma(light_color);
		emissive.xyz = degamma(emissive.xyz + u_emissive_factor);
		planar_reflection_color = degamma(planar_reflection_color);
		reflection_color = degamma(reflection_color);
	}

	if (u_has_planar_reflections == 1 && abs(v_world_position.y) < 0.1)
		color.xyz = mix(color.xyz, planar_reflection_color, 0.5);

	if (u_scene_reflections == 1){
		float reflection_factor = metalness + u_metallic_factor;
		//float reflection_factor = 1.0;
		color.xyz = mix(color.xyz, reflection_color, reflection_factor);
	}

	color *= color_texture;
	// Point
	if (u_light_type == 1){
		computeL_point(LightComp);
	}

	// Spot
	else if (u_light_type == 2){
		computeL_point(LightComp);
		computeSpotFactor(LightComp);
	}

	// Directional
	else if (u_light_type == 3){
		computeL_directional(LightComp);
	}

	computeNdotL(LightComp);

	//we compute the reflection in base to the color and the metalness
	vec3 f0 = mix( vec3(0.5), color.xyz, metalness);

	//metallic materials do not have diffuse
	vec3 diffuseColor = (1.0 - metalness) * color.xyz;

	// METER EN UNA FUNCION
	LightComp.V = normalize(u_camera_position - LightComp.world_position);
	LightComp.H = normalize(LightComp.V + LightComp.L);

	LightComp.NdotH = clamp(dot(LightComp.N, LightComp.H), 0.0, 1.0);
	LightComp.NdotV = clamp(dot(LightComp.N, LightComp.V), 0.0, 1.0);
	LightComp.LdotH = clamp(dot(LightComp.L, LightComp.H), 0.0, 1.0);

	//compute the specular
	vec3 Fr_d = specularBRDF( roughness, f0, LightComp.NdotH, LightComp.NdotV, LightComp.NdotL, LightComp.LdotH);

	// Here we use the Burley, but you can replace it by the Lambert.
	float linearRoughness = pow(roughness, 2.0);
	vec3 Fd_d = diffuseColor * Fd_Burley(LightComp.NdotV,LightComp.NdotL,LightComp.LdotH,linearRoughness); 

	//add diffuse and specular reflection
	vec3 direct = Fr_d + Fd_d;

	if (u_light_cast_shadows == 1){
		testShadowMap(LightComp);
	}

	computeAttenuation(LightComp);

	//compute how much light received the pixel
	vec3 lightParams = light_color * LightComp.att_factor * LightComp.spot_factor * LightComp.shadow_factor;
	//modulate direct light by light received
	light += lightParams * direct;
	light *= color.xyz;;


	// Occlusion
	float occ_factor = met_rough.x;
	occlusion += occ_factor;
	light *= occlusion;

	// Apply other textures
	// Emissive
	light += emissive.xyz;

	// Debug textures
	// Normal
	if (u_texture2show == 1){
		light = LightComp.N;
	}

	// Occlusion
	if(u_texture2show == 2){
		light = vec3(texture( u_met_rough_texture, v_uv ).x);
		light *= texture(u_occlusion_texture, v_uv).x;
	}
	// Emissive
	if(u_texture2show == 3)
		light = emissive.xyz;

	if (u_light_is_first == 0)
		color.a = 0.0;

	FragColor = vec4(light,color.w);
	//FragColor = emissive;
}

//----------------------------- PBR Deferred -------------------------------
\deferred_pbr.fs
#version 330 core

#define PI 3.14159265358979323846
#define RECIPROCAL_PI 0.3183098861837697

in vec2 v_uv;

uniform vec3 u_camera_position;
uniform vec4 u_color;
uniform float u_time;
uniform float u_alpha_cutoff;

//uniform int u_texture2show;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

// Color correction
uniform int u_gamma;

out vec4 FragColor;

#include gbuffer_texture_uniforms
#include light_uniforms
#include normalmap_functions
#include light_functions_multi
#include degamma
#include pbr_functions

void main()
{
	LightComp = LightStruct(
		vec3(0.0, 0.0, 0.0), //L
		vec3(0.0, 0.0, 0.0), //D
		vec3(0.0, 0.0, 0.0), //N
		vec3(0.0, 0.0, 0.0), //V
		vec3(0.0, 0.0, 0.0), //R
		vec3(0.0, 0.0, 0.0), //H

		vec3(0.0, 0.0, 0.0), //World pos

		0.0, // NdotL
		0.0, // LdotD
		0.0, // NdotH
		0.0, // NdotV
		0.0, // LdotH

		0.0, // light dist

		1.0, // spot factor
		1.0, // attenuation factor
		1.0 // shadow_factor
	);

	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	vec4 gb0_color = texture(u_gb0_texture, uv);
	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec4 gb2_color = texture(u_gb2_texture, uv);  
	float ao_factor = texture(u_ssao_texture, uv).x;

	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	LightComp.world_position = proj_worldpos.xyz / proj_worldpos.w;

	LightComp.N = normalize(gb1_color.xyz * 2.0 - vec3(1.0)); // PASAMOS DE [0, 1] A [-1, 1]

	vec4 color = vec4(gb0_color.xyz, 1.0);

	float metalness = gb1_color.w;
	float roughness = gb0_color.w;
	float occlusion = gb2_color.w;

	vec3 ambient_light = u_ambient_light;
	vec3 light_color = u_light_color;
	vec3 light = vec3(0.0);

	if (u_gamma == 1){
		color.xyz = degamma(color.xyz);
		ambient_light = degamma(ambient_light);
		light_color = degamma(light_color);
		gb2_color.xyz = degamma(gb2_color.xyz);
	}

	// Point
	if (u_light_type == 1){
		computeL_point(LightComp);
	}

	// Spot
	else if (u_light_type == 2){
		computeL_point(LightComp);
		computeSpotFactor(LightComp);
	}

	// Directional
	else if (u_light_type == 3){
		computeL_directional(LightComp);
	}

	computeNdotL(LightComp);

	//we compute the reflection in base to the color and the metalness
	vec3 f0 = mix( vec3(0.5), color.xyz, metalness);

	//metallic materials do not have diffuse
	vec3 diffuseColor = (1.0 - metalness) * color.xyz;

	LightComp.V = normalize(u_camera_position - LightComp.world_position);
	LightComp.H = normalize(LightComp.V + LightComp.L);

	LightComp.NdotH = max(dot(LightComp.N, LightComp.H), 0.0);
	LightComp.NdotV = max(dot(LightComp.N, LightComp.V), 0.0);
	LightComp.LdotH = max(dot(LightComp.L, LightComp.H), 0.0);

	//compute the specular
	vec3 Fr_d = specularBRDF( roughness, f0, LightComp.NdotH, LightComp.NdotV, LightComp.NdotL, LightComp.LdotH);

	// Here we use the Burley, but you can replace it by the Lambert.
	float linearRoughness = pow(roughness, 2.0);
	vec3 Fd_d = diffuseColor * Fd_Burley(LightComp.NdotV,LightComp.NdotL,LightComp.LdotH,linearRoughness); 

	//add diffuse and specular reflection
	vec3 direct = Fr_d + Fd_d;

	if (u_light_cast_shadows == 1){
		testShadowMap(LightComp);
	}

	computeAttenuation(LightComp);

	//compute how much light received the pixel
	vec3 lightParams = light_color * LightComp.att_factor * LightComp.spot_factor * LightComp.shadow_factor;

	//modulate direct light by light received
	light += direct * lightParams;
	light += color.xyz * ambient_light * ao_factor; 
	// Apply other textures
	// Emissive
	if(u_emissive_flag == 1)
		light += gb2_color.xyz;

	// Occlusion
	// Occlusion value is only in one coordinate
	light *= occlusion;

	//FragColor = vec4(texture(u_gb2_texture, uv).w);
	FragColor = vec4(light, 1.0);
}

//-------------------------------- SSAO --------------------------------------
\ssao.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_gb1_texture;
uniform sampler2D u_depth_texture;

uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_points[64];

#include ssao_functions

out vec4 FragColor;
void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	float depth = texture( u_depth_texture, uv ).x;

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	vec4 original_point = gl_FragCoord;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0 );
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	const int samples = 64;
	float num = samples; //num inicial de muestras que no estan ocluidas

	//for every sample around the point
	for( int i = 0; i < samples; ++i )
	{
		//compute is world position using the random
		vec3 delta = u_points[i] * 10.0;
		float angle = gl_FragCoord.x * 1013.89 + gl_FragCoord.y * 1031.41;
		delta = rotateY( angle, delta );
		vec3 p = world_position + delta;

		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(p,1.0);  // multiplicar por la view para estar en screen space
		proj.xy /= proj.w; //convert to clipspace from homogeneous

		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - 0.005) / proj.w;  // sin este bias un pixel se puede ocluir a si mismo
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]

		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;

		//compare true depth with its depth
		float diff = proj.z - pdepth;
		if( diff > 0.0 && diff < 0.001 ) //if true depth smaller, is inside
		{
			float x_mod = pow((u_points[i].x), 2);
			float y_mod = pow((u_points[i].y), 2);
			float z_mod = pow((u_points[i].z), 2);
			float dist = sqrt(x_mod + y_mod + z_mod);

			num = num - dist; //remove this point from the list of visible
		}
	}

	//finally, compute the AO factor as the ratio of visible points
	float ao = float(num) / float(samples);

	FragColor = vec4(ao);

}

//----------------------------------- SSAO Plus ------------------------------
\ssao_plus.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_gb1_texture;
uniform sampler2D u_depth_texture;

uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_points[64];

#include ssao_functions

out vec4 FragColor;
void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	float depth = texture( u_depth_texture, uv ).x;
	vec3 gb1_color = texture(u_gb1_texture, uv).xyz; //desconvertir rango
	vec3 normal = normalize(gb1_color * 2.0 - vec3(1.0));

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	vec4 original_point = gl_FragCoord;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0 );
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	const int samples = 64;
	float num = samples; //inicial non-occluded samples

	//to create the matrix33 to convert from tangent to world
	mat3 rotmat = cotangent_frame( normal, world_position, uv );

	//for every sample around the point
	for( int i = 0; i < samples; ++i )
	{
		//compute is world position using the random
		vec3 delta = u_points[i] * 10.0;
		vec3 p = world_position + delta;

		//rotate a point is easy
		vec3 rotated_point = world_position + rotmat * delta;

		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(rotated_point,1.0);  // multiplicar por la view para estar en screen space
		proj.xy /= proj.w; //convert to clipspace from homogeneous

		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - 0.005) / proj.w;  // sin este bias un pixel se puede ocluir a si mismo
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]

		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;

		//compare true depth with its depth
		float diff = proj.z - pdepth;
		if( diff > 0.0 && diff < 0.001 ) //if true depth smaller, is inside
		{
			float x_mod = pow((u_points[i].x), 2);
			float y_mod = pow((u_points[i].y), 2);
			float z_mod = pow((u_points[i].z), 2);
			float dist = sqrt(x_mod + y_mod + z_mod);

			num = num - dist; //remove this point from the list of visible
		}
	}

	//finally, compute the AO factor as the ratio of visible points
	float ao = float(num) / float(samples);

	FragColor = vec4(ao);
}

//---------------------------------- Probe ----------------------------------------
\probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec3 u_coeffs[9];

out vec4 FragColor;

#include irradiance_functions

void main()
{
	SH9Color sh;
	// UN POCO CUTRE -- GUARDAMOS TODOS LOS COEFICIENTES EN LA ESTRUCTURA
	sh.c[0] = u_coeffs[0];
	sh.c[1] = u_coeffs[1];
	sh.c[2] = u_coeffs[2];
	sh.c[3] = u_coeffs[3];
	sh.c[4] = u_coeffs[4];
	sh.c[5] = u_coeffs[5];
	sh.c[6] = u_coeffs[6];
	sh.c[7] = u_coeffs[7];
	sh.c[8] = u_coeffs[8];

	// COGER DE LA TEXTURA
	vec3 N = normalize(v_normal);
	//now we can use the coefficients to compute the irradiance
	vec3 irradiance = ComputeSHIrradiance( N, sh );

	//fill the coefficients
	//const float d_uvx = 1.0 / 9.0;
	//for(int i = 0; i < 9; ++i)
	//{
	//	vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
	//	sh.c[i] = texture( u_probes_texture, coeffs_uv).xyz;
	//}

	FragColor = vec4(irradiance,1.0);
}

//-------------------------------- Irradiance Deferred --------------------------------------

\irradiance_deferred.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_irr_texture;
uniform sampler2D u_ssao_texture;

uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_irr_start;
uniform vec3 u_irr_end;
uniform vec3 u_irr_dim;
uniform vec3 u_irr_delta;
uniform float u_num_probes;
uniform float u_irr_normal_distance;

out vec4 FragColor;

#include irradiance_functions

void main()
{
	// HAY QUE HACER CONTROL DE GAMMA
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	vec4 gb0_color = texture(u_gb0_texture, uv);
	vec4 gb1_color = texture(u_gb1_texture, uv);
	float ssao_factor = texture(u_ssao_texture, uv).x;
	float depth = texture( u_depth_texture, uv ).x;
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	//vec4 original_point = gl_FragCoord;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0 );
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	// CONVERTIMOS LA COORDENADA DE MUNDO DE WORLD SPACE A "GRID SPACE", Y UNA VEZ
	// SABEMOS DONDE ESTÁ COLOCADO EL PUNTO DENTRO DE LA GRID, NOS CARGAMOS EL DECIMAL
	// Y SABEMOS EXACTAMENTE EN QUE FILA Y COLUMNA ESTÁ. ASÍ PODEMOS SABER QUE PROBE ESTÁ MÁS CERCA
	//computing nearest probe index based on world position
	vec3 irr_range = u_irr_end - u_irr_start;
	vec3 irr_local_pos = clamp( world_position - u_irr_start + N * u_irr_normal_distance, vec3(0.0), irr_range );  //offset a little

	//convert from world pos to grid pos
	vec3 irr_norm_pos = irr_local_pos / u_irr_delta;
	//round values as we cannot fetch between rows for now
	vec3 local_indices = round( irr_norm_pos );
	//compute in which row is the probe stored
	float row = local_indices.x + local_indices.y * u_irr_dim.x + local_indices.z * u_irr_dim.x * u_irr_dim.y;
	//find the UV.y coord of that row in the probes texture
	float row_uv = (row + 1.0) / (u_num_probes + 1.0);

	SH9Color sh;
	//fill the coefficients
	const float d_uvx = 1.0 / 9.0;
	for(int i = 0; i < 9; ++i)
	{
	vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
	// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
	sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}
	//now we can use the coefficients to compute the irradiance
	vec3 irradiance = ComputeSHIrradiance( N, sh );

	vec3 color = gb0_color.xyz * irradiance * ssao_factor;
	FragColor = vec4(color, 1.0);

}

//-------------------------------- Irradiance Forward --------------------------------------

\irradiance_forward.fs
#version 330 core

in vec2 v_uv;
in vec3 v_world_position;
in vec3 v_normal;

uniform sampler2D u_texture;
uniform sampler2D u_irr_texture;
uniform sampler2D u_normal_texture;

uniform vec3 u_camera_position;
uniform int u_normal_text_bool;
uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_irr_start;
uniform vec3 u_irr_end;
uniform vec3 u_irr_dim;
uniform vec3 u_irr_delta;
uniform float u_num_probes;
uniform float u_irr_normal_distance;

out vec4 FragColor;

#include normalmap_functions
#include irradiance_functions

void main()
{
	// HAY QUE HACER CONTROL DE GAMMA
	vec2 uv = v_uv;
	vec4 color = texture(u_texture, uv);

	vec3 world_position = v_world_position;

	vec3 N = normalize(v_normal);
	vec3 V = normalize(u_camera_position - world_position);
	vec3 normal_pixel = texture(u_normal_texture, uv).xyz;
	if (u_normal_text_bool == 1)
		N = perturbNormal(N, V, uv, normal_pixel);

	// CONVERTIMOS LA COORDENADA DE MUNDO DE WORLD SPACE A "GRID SPACE", Y UNA VEZ
	// SABEMOS DONDE ESTÁ COLOCADO EL PUNTO DENTRO DE LA GRID, NOS CARGAMOS EL DECIMAL
	// Y SABEMOS EXACTAMENTE EN QUE FILA Y COLUMNA ESTÁ. ASÍ PODEMOS SABER QUE PROBE ESTÁ MÁS CERCA
	//computing nearest probe index based on world position
	vec3 irr_range = u_irr_end - u_irr_start;
	vec3 irr_local_pos = clamp( world_position - u_irr_start + N * u_irr_normal_distance, vec3(0.0), irr_range );  //offset a little
	
	//convert from world pos to grid pos
	vec3 irr_norm_pos = irr_local_pos / u_irr_delta;
	//floor instead of round
	vec3 local_indices = floor( irr_norm_pos );

	//now we have the interpolation factors
	vec3 factors = irr_norm_pos - local_indices; 

	//compute in which row is the probe stored
	float row = local_indices.x + local_indices.y * u_irr_dim.x + local_indices.z * u_irr_dim.x * u_irr_dim.y;

	//find the UV.y coord of that row in the probes texture
	float row_uv = (row + 1.0) / (u_num_probes + 1.0);

	SH9Color sh;
	//fill the coefficients
	const float d_uvx = 1.0 / 9.0;
	vec2 coeffs_uv;
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	//example for right bottom far index
	// Right, Bottom, Far
	vec3 indicesRBF = local_indices; // BLUEPRINT
	indicesRBF += vec3(1.0); //from left to right
	//compute in which row is the probe stored
	row = indicesRBF.x + indicesRBF.y * u_irr_dim.x + indicesRBF.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrRBF = ComputeSHIrradiance( N, sh );

	// Left,Bottom,Far
	vec3 indicesLBF = local_indices;
	indicesLBF += vec3(-1.0, 1.0, 1.0);
	//compute in which row is the probe stored
	row = indicesLBF.x + indicesLBF.y * u_irr_dim.x + indicesLBF.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrLBF = ComputeSHIrradiance( N, sh );

	// Right,Top,Far
	vec3 indicesRTF = local_indices;
	indicesRTF += vec3(1.0, -1.0, 1.0); //from left to right
	//compute in which row is the probe stored
	row = indicesRTF.x + indicesRTF.y * u_irr_dim.x + indicesRTF.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrRTF = ComputeSHIrradiance( N, sh );

	// Left,Top,Far
	vec3 indicesLTF = local_indices;
	indicesLTF += vec3(-1.0, -1.0, 1.0); //from left to right
	//compute in which row is the probe stored
	row = indicesLTF.x + indicesLTF.y * u_irr_dim.x + indicesLTF.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrLTF = ComputeSHIrradiance( N, sh );

	// Right, Bottom,Close
	vec3 indicesRBN = local_indices; // BLUEPRINT
	indicesRBN += vec3(1.0, 1.0, -1.0); //from left to right
	//compute in which row is the probe stored
	row = indicesRBN.x + indicesRBN.y * u_irr_dim.x + indicesRBN.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrRBN = ComputeSHIrradiance( N, sh );

	// Left,Bottom,Close
	vec3 indicesLBN = local_indices;
	indicesLBN = indicesLBF + vec3(-1.0, 1.0, -1.0);
	//compute in which row is the probe stored
	row = indicesLBN.x + indicesLBN.y * u_irr_dim.x + indicesLBN.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrLBN = ComputeSHIrradiance( N, sh );

	// Right,Top,Close
	vec3 indicesRTN = local_indices;
	indicesRTN += vec3(1.0, -1.0, -1.0); //from left to right
	//compute in which row is the probe stored
	row = indicesRTN.x + indicesRTN.y * u_irr_dim.x + indicesRTN.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrRTN = ComputeSHIrradiance( N, sh );

	// Left,Top,Close
	vec3 indicesLTN = local_indices;
	indicesLTN += vec3(-1.0); //from left to right
	//compute in which row is the probe stored
	row = indicesLTN.x + indicesLTN.y * u_irr_dim.x + indicesLTN.z * u_irr_dim.x * u_irr_dim.y;
	
	//find the UV.y coord of that row in the probes texture
	row_uv = (row + 1.0) / (u_num_probes + 1.0);

	//fill the coefficients
	for(int i = 0; i < 9; ++i)
	{
		coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		// LEEMOS DE LA TEXTURA PROBES TEXTURE Y LLAMAMOS A LA FUNCIÓN COMPUTESHIRR
		sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
	}

	vec3 irrLTN = ComputeSHIrradiance( N, sh );

	vec3 irrTF = mix( irrLTF, irrRTF, factors.x );
	vec3 irrBF = mix( irrLBF, irrRBF, factors.x );
	vec3 irrTN = mix( irrLTN, irrRTN, factors.x );
	vec3 irrBN = mix( irrLBN, irrRBN, factors.x );

	vec3 irrT = mix( irrTF, irrTN, factors.z );
	vec3 irrB = mix( irrBF, irrBN, factors.z );

	vec3 irradiance = mix( irrB, irrT, factors.y );

	color.xyz *= irradiance;
	FragColor = vec4(color);

}

//-------------------------------- Reflections deferred --------------------------------------

\reflections_deferred.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_depth_texture;
// MIRAR SI SE PUEDEN IMPORTAR
uniform sampler2D u_screen_texture;
uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform samplerCube u_skybox_texture;
uniform int u_scene_reflections;

uniform int u_gamma;

uniform vec3 u_camera_position;
uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

//#include light_uniforms
#include degamma

out vec4 FragColor;

const int SAMPLES = 64;

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	vec4 color = texture(u_screen_texture, uv);
	float depth = texture( u_depth_texture, uv ).x;
	vec4 gb0_color = texture(u_gb0_texture, uv);
	vec4 gb1_color = texture(u_gb1_texture, uv);
	float roughness = gb0_color.w;
	float metalness = gb1_color.w;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	vec3 V = normalize(world_position - u_camera_position);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));
	vec3 R = reflect(V, N);

	vec3 reflection_color = vec3(0.0);
	reflection_color = textureLod(u_skybox_texture, R, roughness * 4.0).xyz;
	//reflection_color = texture(u_skybox_texture, R).xyz;

	if (u_gamma == 1){
		reflection_color = degamma(reflection_color);
	}

	//reflection_factor = 1.0;
	float reflection_factor = metalness;
	color.xyz = mix(color.xyz, reflection_color, reflection_factor);

	FragColor = color;
	//FragColor = texture(u_screen_texture, uv);
	//FragColor = vec4(N, 1.0); 
	//FragColor = vec4(0.0, 1.0, 0.0, 1.0); 

}


//-------------------------------- Volumetric Deferred --------------------------------------

\volumetric_deferred.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform sampler2D u_ssao_texture;

uniform vec3 u_camera_position;
uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform float u_air_density;

#include light_uniforms


out vec4 FragColor;

const int SAMPLES = 64;

float testShadowMap(vec3 current_pos){
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_light_shadowmap_vpm * vec4(current_pos, 1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;
	
	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_light_shadow_bias) / proj_pos.w;
	
	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;
	
	//read depth from depth buffer in [0..+1] non-linear
	vec4 scale_factor = u_map_piece;
	vec2 sh_uv = vec2(shadow_uv.x*scale_factor[0] + scale_factor[2], shadow_uv.y*scale_factor[1] + scale_factor[3]);
	float shadow_depth = texture( u_light_shadowmap, sh_uv).x;
	
	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	
	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		shadow_factor = 0.0;
		
	//We must see if it is outside the sides
	if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
		shadow_factor = 1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor = 1.0;

	return shadow_factor;
}

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	//float ssao_factor = texture(u_ssao_texture, uv).x;
	float depth = texture( u_depth_texture, uv ).x;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0 );
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	vec3 color = vec3(0.0);

	vec3 ray_start = u_camera_position;
	vec3 ray_dir = world_position - ray_start;
	float ray_length = length(ray_dir);
	ray_dir /= ray_length;
	ray_length = min(500.0, ray_length);

	float step_dist = ray_length / float(SAMPLES);
	// LIMITAMOS EL STEP DIST
	vec3 current_pos = ray_start;
	vec3 ray_offset = ray_dir * step_dist;

	//how visible is the point at the end of the ray
	// ESTE TRANSPARENCY IRÁ ITERANDO PARA SABER EL ALPHA UNA VEZ RECORRIDO TODO EL RAYO
	float transparency = 1.0;
	vec3 irradiance = vec3(0.0);

	// To know how much shadows are within light
	for(int i = 0; i < SAMPLES; ++i)
	{
		//evaluate contribution
		//compute illumination in this point
		float shadow = testShadowMap(current_pos);
		vec3 light = u_light_color * shadow;

		// CON ESTO PODEMOS HACER QUE FACILMENTE FUNCIONE TAMBIÉN PARA SPOLIGHT
		//light *= att;

		//accumulate the amount of light
		irradiance += light * transparency * (u_air_density * step_dist);

		//reduce visibility -- AIR DENSITY Y STEP SON PROPORCIONALES: CUANTO MÁS AVANZAMOS MÁS AIRE HAY DE POR MEDIO
		transparency -= u_air_density * step_dist;

		//too dense, nothing can be seen behind
		if( transparency < 0.001 )
			break;

		//advance to next position
		current_pos.xyz += ray_offset;
	}

	// ESTO ES SOLO POR QUE A JAVI NO LE FUNCIONABA, PERO LA FORMA CORRECTA DE HACERLO ES LA DE LAS SLIDES
	//irradiance = vec3(1.0) * in_light /float(SAMPLES);

	//irradiance = vec3(1.0, 0.0, 0.0);
	FragColor = vec4(irradiance, 1.0 - transparency);
	//FragColor = vec4(1.0, 0.0, 0.0, 1.0 - transparency);

}

//-------------------------------- Volumetric Deferred Non directional --------------------------------------

\volumetric_deferred_nondir.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform sampler2D u_ssao_texture;

uniform vec3 u_camera_position;
uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform float u_air_density;

#include light_uniforms


out vec4 FragColor;

const int SAMPLES = 64;

float testShadowMap(vec3 current_pos){
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_light_shadowmap_vpm * vec4(current_pos, 1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;
	
	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_light_shadow_bias) / proj_pos.w;
	
	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;
	
	//read depth from depth buffer in [0..+1] non-linear
	vec4 scale_factor = u_map_piece;
	vec2 sh_uv = vec2(shadow_uv.x*scale_factor[0] + scale_factor[2], shadow_uv.y*scale_factor[1] + scale_factor[3]);
	float shadow_depth = texture( u_light_shadowmap, sh_uv).x;
	
	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	
	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		shadow_factor = 0.0;
		
	//We must see if it is outside the sides
	if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
		shadow_factor = 1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor = 1.0;

	return shadow_factor;
}

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	//float ssao_factor = texture(u_ssao_texture, uv).x;
	float depth = texture( u_depth_texture, uv ).x;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0 );
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	vec3 color = vec3(0.0);

	vec3 ray_start = u_camera_position;
	vec3 ray_dir = world_position - ray_start;
	float ray_length = length(ray_dir);
	ray_dir /= ray_length;
	ray_length = min(500.0, ray_length);

	float step_dist = ray_length / float(SAMPLES);
	// LIMITAMOS EL STEP DIST
	vec3 current_pos = ray_start;
	vec3 ray_offset = ray_dir * step_dist;

	//how visible is the point at the end of the ray
	// ESTE TRANSPARENCY IRÁ ITERANDO PARA SABER EL ALPHA UNA VEZ RECORRIDO TODO EL RAYO
	float transparency = 1.0;
	vec3 irradiance = vec3(0.0);

	// To know how much shadows are within light
	for(int i = 0; i < SAMPLES; ++i)
	{
		//vec3 light = u_light_color;
		vec3 D = normalize(u_light_direction);
		vec3 L = u_light_position - current_pos;
		float light_dist = length(L);
		L = L/light_dist;

		float LdotD = dot(-L, D);
		// check if point inside the spotlight
		float spot_factor = 0.0;
		if (LdotD >= u_light_cone_cos){
			spot_factor = pow(LdotD, u_light_cone_exp);
		}
		else{
			transparency = 1.0;
		}

		float att_factor = u_light_max_distance - light_dist;
		att_factor /= u_light_max_distance;
		att_factor = max(att_factor, 0.0);
		// apply quadratic attenuation
		float att = pow(att_factor,2);

		//evaluate contribution
		//compute illumination in this point
		float shadow = testShadowMap(current_pos);
		vec3 light = u_light_color * shadow * spot_factor;// * att;

		//accumulate the amount of light
		irradiance += light * transparency * (u_air_density * step_dist);

		//reduce visibility -- AIR DENSITY Y STEP SON PROPORCIONALES: CUANTO MÁS AVANZAMOS MÁS AIRE HAY DE POR MEDIO
		transparency -= u_air_density * step_dist;

		//too dense, nothing can be seen behind
		if( transparency < 0.001 )
			break;

		//advance to next position
		current_pos.xyz += ray_offset;
	}

	FragColor = vec4(irradiance, 1.0 - transparency);
	//FragColor = debug_color;

}

//-------------------------------- Decals --------------------------------------

\decal.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_gb2_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_decal_texture;

uniform vec3 u_camera_position;
uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform mat4 u_imodel;

out vec4 FragColor;

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	float depth = texture( u_depth_texture, uv ).x;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0 );
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	// COGEMOS LA COORDENADA LOCAL A PARTIR DE LA DE MUNDO CON LA INVERSA DE LA MODEL
	vec3 local_pos = (u_imodel * vec4(world_position, 1.0)).xyz;

	// MIRAMOS SI ESTÁ DENTRO DE LO QUE NOS INTERESA .DE ESTA FORMA, SOLO PINTAMOS LA PARTE DEL CUBO QUE TOCA CON EL OBJETO Y PARECE QUE SE PEGUE
	// ESTO ES ASI POR QUE EL CUBO VA DE -1 A 1 EN TODAS LAS COORDENADAS.
	if (local_pos.x < -1.0 || local_pos.x > 1.0 ||
		local_pos.y < -1.0 || local_pos.y > 1.0 ||
		local_pos.z < -1.0 || local_pos.z > 1.0 )
		discard;

	vec2 decal_uv = local_pos.xy*0.5+vec2(0.5);
	//vec4 color = vec4(1.0, 0.0, 0.0, 1.0);
	vec4 color = texture(u_decal_texture, decal_uv);

	FragColor = color;
	//FragColor = vec4(color.xyz, 1.0);

}

//------------------------------- Reflection Probe -----------------------------
\reflection_probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
uniform vec3 u_camera_pos;
uniform samplerCube u_texture;

out vec4 FragColor;

void main()
{
	vec3 V = v_world_position - u_camera_pos;
	vec3 N = normalize(v_normal);
	vec3 R = reflect(V, N);
	// TEXTURE LOD HACE QUE EL MITMMAP QUE SE USE SEA SIEMPRE EL MISMO Y NO SE BAJE EN FUNCIÓN DE LA DISTANCIA
	// Y EL NUMERO DEL FINAL ES EL MITMAP EN EL QUE ESTAMOS. CUANTO MÁS ALTO MÁS BLURREADO ESTARÁ -- BAJAMOS DE MITMAO 
	FragColor = textureLod(u_texture, R, 1.0);
}

//--------------------------------- Saturation -------------------------------
\saturation.fs
#version 330 core

in vec2 v_uv;
uniform sampler2D u_texture;
uniform float u_vigneting;
uniform float u_saturation;

out vec4 FragColor;

void main(){
	vec2 ucv = v_uv;
	vec4 color = texture(u_texture, v_uv);
	vec3 desaturated = vec3((color.x + color.y + color.z)/ 3.0);
	color.xyz = mix(desaturated, color.xyz, u_saturation);
	//color.xyz = vec3((color.x + color.y + color.z)/3.0);
	
	vec3 vigneted = color.xyz * pow(1.2 - length(v_uv - vec2(0.5, 0.5)), 4.0);
	color.xyz = mix(color.xyz, vigneted, u_vigneting);

	FragColor = color;
}

//--------------------------------- Lens distortion -------------------------------
\lens_distortion.fs
#version 330 core

in vec2 v_uv;
uniform sampler2D u_texture;
const float PI = 3.14159265359;

out vec4 FragColor;

void main(){
	vec2 uv = v_uv;
	uv = sin(uv*PI*2)*0.1+uv;
	vec4 color = texture(u_texture, uv);

	FragColor = color;
}

//--------------------------------- Contrast -------------------------------
\contrast.fs
#version 330 core

in vec2 v_uv;
uniform sampler2D u_texture;
uniform float u_intensity;
const float PI = 3.14159265359;

out vec4 FragColor;

void main(){
	vec2 uv = v_uv;
	vec4 color = texture(u_texture, uv);
	// LOS QUE ESTÉN POR DEBAJO DE 0.5 SERÁN MÁS PEQUEÑOS Y LOS QUE ESTÉN POR ENCIMA MÁS GRANDES
	color.xyz = (color.xyz - vec3(0.5)) * u_intensity + vec3(0.5);

	FragColor = color;
}

//--------------------------------- Blur -------------------------------
\blur.fs
#version 330 core

in vec2 v_uv;
precision highp float;
uniform sampler2D u_texture;
uniform vec2 u_offset;
uniform float u_intensity;
out vec4 FragColor;

void main() {
//linear blur shader of 9 samples
   vec4 sum = vec4(0.0);
   sum += texture2D(u_texture, v_uv + u_offset * -4.0) * 0.05/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * -3.0) * 0.09/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * -2.0) * 0.12/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * -1.0) * 0.15/0.98;
   sum += texture2D(u_texture, v_uv) * 0.16/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * 4.0) * 0.05/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * 3.0) * 0.09/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * 2.0) * 0.12/0.98;
   sum += texture2D(u_texture, v_uv + u_offset * 1.0) * 0.15/0.98;
   
   FragColor = u_intensity * sum;
}

//--------------------------------- Threshold -------------------------------
\threshold.fs
#version 330 core

in vec2 v_uv;
precision highp float;
uniform sampler2D u_texture;
uniform sampler2D u_textureB;
uniform float u_threshold;
out vec4 FragColor;

void main() {
   vec4 color = texture2D(u_texture, v_uv);
   if (color.x < u_threshold)
		color.x = 0.0;
   if (color.y < u_threshold)
		color.y = 0.0;
   if (color.z < u_threshold)
		color.z = 0.0;

   FragColor = color;
}

//--------------------------------- Mix -------------------------------
\mix.fs
#version 330 core

in vec2 v_uv;
precision highp float;
uniform sampler2D u_texture;
uniform sampler2D u_textureB;
uniform float u_intensity;
out vec4 FragColor;

void main() {
   vec4 colorA = texture2D(u_texture, v_uv);
   vec4 colorB = texture2D(u_textureB, v_uv);
   FragColor = colorA * u_intensity + colorB;
}

//--------------------------------- Motionblur -------------------------------
\motionblur.fs
#version 330 core

in vec2 v_uv;
precision highp float;
uniform sampler2D u_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_viewprojection_last;
uniform mat4 u_inverse_viewprojection;
out vec4 FragColor;

void main() {
	vec2 uv = v_uv;

   	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	// get position of the point in the last frame
	vec4 last_pos_cs = u_viewprojection_last * vec4(world_position, 1.0);
	last_pos_cs.xyz /= last_pos_cs.w;
	// go from 0 to 1
	vec2 uv2 = last_pos_cs.xy * 0.5 + vec2(0.5);

	vec4 color = vec4(0.0);
	const int SAMPLES = 16;
	for (int i = 0; i < SAMPLES; i++){
		float interpolation_f = float(i)/float(SAMPLES);
		// interpolate uvs between current and last frames
		vec2 interpolated_uv = mix(uv, uv2, interpolation_f);
		color += texture2D(u_texture, interpolated_uv);
	}
	// average
	color /= float(SAMPLES);
   	FragColor = color;
}
//--------------------------------- Depth Of Field -------------------------------
\depth_field.fs
#version 330 core

in vec2 v_uv;
precision highp float;
uniform sampler2D u_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_lin_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec3 u_camera_position;
uniform vec2 u_iRes;

uniform float u_focal_length;
uniform float u_focal_range;
//uniform float u_apperture;
//uniform float u_plane_focus;
uniform float u_standard_deviation;
uniform float u_gaussian_comp;

uniform vec2 u_offset;
uniform float u_intensity;
out vec4 FragColor;


const float E = 2.71828182845;

void main() {
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	vec4 color = texture(u_texture, uv);
   	float depth = texture( u_depth_texture, uv ).x;
   	float lin_depth = texture( u_lin_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	float camera_dist = length(world_position - u_camera_position);
	//float CoC_num = u_apperture * (u_focal_length * (u_plane_focus - depth));
	//float CoC_den = depth * (u_plane_focus - u_focal_length);
	//float CoC = abs(CoC_num / CoC_den);
	float CoC = (lin_depth - u_focal_length) / u_focal_range;

	CoC = clamp(CoC, 0.0, 20);
	//vec3 camera_dist = world_position - u_camera_position;

	//vec3 offset_vec = camera_dist - u_focal_length;
	//float offset = length(offset_vec);

	vec4 sum = vec4(0.0);
	for (int i = 0; i < CoC; i++){
		float offset = (i/(CoC-1) - 0.5) * 1.0;
		float deviation_squared = u_standard_deviation*u_standard_deviation;
		float gauss = u_gaussian_comp * pow(E, -((offset*offset)/(2*deviation_squared)));
		float sample_dist = i - floor(CoC/2);
		sum += texture2D(u_texture, uv + offset * sample_dist) * gauss;
		//sum += texture2D(u_texture, uv + u_offset * sample_dist) * gauss;
	}

	vec4 final_blur = sum;

  	FragColor = color;
  	//FragColor = vec4(CoC);
}

// ---------------------------------- Antialiasing ---------------------------------
\antialiasing.fs
#version 330 core

in vec2 v_uv;
uniform sampler2D u_texture;
uniform vec2 u_viewportSize;
uniform vec2 u_iViewportSize;
#define FXAA_REDUCE_MIN (1.0/ 128.0)
#define FXAA_REDUCE_MUL (1.0 / 8.0)
#define FXAA_SPAN_MAX 8.0

out vec4 FragColor;

void main(){
	vec4 color = vec4(0.0);
	// MEJOR PASARLO POR PARAMETRO?
	vec2 fragCoord = gl_FragCoord.xy;
	vec3 rgbNW = texture2D(u_texture, (fragCoord + vec2(-1.0, -1.0)) * u_iViewportSize).xyz;
	vec3 rgbNE = texture2D(u_texture, (fragCoord + vec2(1.0, -1.0)) * u_iViewportSize).xyz;
	vec3 rgbSW = texture2D(u_texture, (fragCoord + vec2(-1.0, 1.0)) * u_iViewportSize).xyz;
	vec3 rgbSE = texture2D(u_texture, (fragCoord + vec2(1.0, 1.0)) * u_iViewportSize).xyz;
	vec3 rgbM  = texture2D(u_texture, fragCoord  * u_iViewportSize).xyz;
	vec3 luma = vec3(0.299, 0.587, 0.114);
	float lumaNW = dot(rgbNW, luma);
	float lumaNE = dot(rgbNE, luma);
	float lumaSW = dot(rgbSW, luma);
	float lumaSE = dot(rgbSE, luma);
	float lumaM  = dot(rgbM,  luma);
	float lumaMin = min(lumaM, min(min(lumaNW, lumaNE), min(lumaSW, lumaSE)));
	float lumaMax = max(lumaM, max(max(lumaNW, lumaNE), max(lumaSW, lumaSE)));

	vec2 dir;
	dir.x = -((lumaNW + lumaNE) - (lumaSW + lumaSE));
	dir.y =  ((lumaNW + lumaSW) - (lumaNE + lumaSE));

	float dirReduce = max((lumaNW + lumaNE + lumaSW + lumaSE) * (0.25 * FXAA_REDUCE_MUL), FXAA_REDUCE_MIN);

	float rcpDirMin = 1.0 / (min(abs(dir.x), abs(dir.y)) + dirReduce);
	dir = min(vec2(FXAA_SPAN_MAX, FXAA_SPAN_MAX), max(vec2(-FXAA_SPAN_MAX, -FXAA_SPAN_MAX), dir * rcpDirMin)) * u_iViewportSize;

	vec3 rgbA = 0.5 * (texture2D(u_texture, fragCoord * u_iViewportSize + dir * (1.0 / 3.0 - 0.5)).xyz +
		texture2D(u_texture, fragCoord * u_iViewportSize + dir * (2.0 / 3.0 - 0.5)).xyz);
	vec3 rgbB = rgbA * 0.5 + 0.25 * (texture2D(u_texture, fragCoord * u_iViewportSize + dir * -0.5).xyz +
		texture2D(u_texture, fragCoord * u_iViewportSize + dir * 0.5).xyz);

	//return vec4(rgbA,1.0);
	float lumaB = dot(rgbB, luma);
	if ((lumaB < lumaMin) || (lumaB > lumaMax))
		color = vec4(rgbA, 1.0);
	else
		color = vec4(rgbB, 1.0);
	
	FragColor = color;
}

//--------------------------------- Skybox -------------------------------
\skybox.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
uniform vec3 u_camera_pos;
uniform samplerCube u_texture;

out vec4 FragColor;

void main()
{
	vec3 V = v_world_position - u_camera_pos;
	FragColor = texture(u_texture, V);
}

//---------------------------------- Depth ----------------------------------------
\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}

//---------------------------------- Instanced ----------------------------------------

\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}